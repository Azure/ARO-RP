// Code generated by github.com/bennerv/go-cosmosdb, DO NOT EDIT.

package cosmosdb

import (
	"context"
	"fmt"
	"net/http"
	"sync"

	"github.com/ugorji/go/codec"

	pkg "github.com/Azure/ARO-RP/pkg/api"
)

type fakeOpenShiftClusterDocumentTriggerHandler func(context.Context, *pkg.OpenShiftClusterDocument) error
type fakeOpenShiftClusterDocumentQueryHandler func(OpenShiftClusterDocumentClient, *Query, *Options) OpenShiftClusterDocumentRawIterator

var _ OpenShiftClusterDocumentClient = &FakeOpenShiftClusterDocumentClient{}

// NewFakeOpenShiftClusterDocumentClient returns a FakeOpenShiftClusterDocumentClient
func NewFakeOpenShiftClusterDocumentClient(h *codec.JsonHandle) *FakeOpenShiftClusterDocumentClient {
	return &FakeOpenShiftClusterDocumentClient{
		jsonHandle:                h,
		openShiftClusterDocuments: make(map[string]*pkg.OpenShiftClusterDocument),
		triggerHandlers:           make(map[string]fakeOpenShiftClusterDocumentTriggerHandler),
		queryHandlers:             make(map[string]fakeOpenShiftClusterDocumentQueryHandler),
	}
}

// FakeOpenShiftClusterDocumentClient is a FakeOpenShiftClusterDocumentClient
type FakeOpenShiftClusterDocumentClient struct {
	lock                      sync.RWMutex
	jsonHandle                *codec.JsonHandle
	openShiftClusterDocuments map[string]*pkg.OpenShiftClusterDocument
	triggerHandlers           map[string]fakeOpenShiftClusterDocumentTriggerHandler
	queryHandlers             map[string]fakeOpenShiftClusterDocumentQueryHandler
	sorter                    func([]*pkg.OpenShiftClusterDocument)
	etag                      int
	changeFeedIterators       []*fakeOpenShiftClusterDocumentIterator

	// returns true if documents conflict
	conflictChecker func(*pkg.OpenShiftClusterDocument, *pkg.OpenShiftClusterDocument) bool

	// err, if not nil, is an error to return when attempting to communicate
	// with this Client
	err error
}

// SetError sets or unsets an error that will be returned on any
// FakeOpenShiftClusterDocumentClient method invocation
func (c *FakeOpenShiftClusterDocumentClient) SetError(err error) {
	c.lock.Lock()
	defer c.lock.Unlock()

	c.err = err
}

// SetSorter sets or unsets a sorter function which will be used to sort values
// returned by List() for test stability
func (c *FakeOpenShiftClusterDocumentClient) SetSorter(sorter func([]*pkg.OpenShiftClusterDocument)) {
	c.lock.Lock()
	defer c.lock.Unlock()

	c.sorter = sorter
}

// SetConflictChecker sets or unsets a function which can be used to validate
// additional unique keys in a OpenShiftClusterDocument
func (c *FakeOpenShiftClusterDocumentClient) SetConflictChecker(conflictChecker func(*pkg.OpenShiftClusterDocument, *pkg.OpenShiftClusterDocument) bool) {
	c.lock.Lock()
	defer c.lock.Unlock()

	c.conflictChecker = conflictChecker
}

// SetTriggerHandler sets or unsets a trigger handler
func (c *FakeOpenShiftClusterDocumentClient) SetTriggerHandler(triggerName string, trigger fakeOpenShiftClusterDocumentTriggerHandler) {
	c.lock.Lock()
	defer c.lock.Unlock()

	c.triggerHandlers[triggerName] = trigger
}

// SetQueryHandler sets or unsets a query handler
func (c *FakeOpenShiftClusterDocumentClient) SetQueryHandler(queryName string, query fakeOpenShiftClusterDocumentQueryHandler) {
	c.lock.Lock()
	defer c.lock.Unlock()

	c.queryHandlers[queryName] = query
}

func (c *FakeOpenShiftClusterDocumentClient) deepCopy(openShiftClusterDocument *pkg.OpenShiftClusterDocument) (*pkg.OpenShiftClusterDocument, error) {
	var b []byte
	err := codec.NewEncoderBytes(&b, c.jsonHandle).Encode(openShiftClusterDocument)
	if err != nil {
		return nil, err
	}

	openShiftClusterDocument = nil
	err = codec.NewDecoderBytes(b, c.jsonHandle).Decode(&openShiftClusterDocument)
	if err != nil {
		return nil, err
	}

	return openShiftClusterDocument, nil
}

func (c *FakeOpenShiftClusterDocumentClient) apply(ctx context.Context, partitionkey string, openShiftClusterDocument *pkg.OpenShiftClusterDocument, options *Options, isCreate bool) (*pkg.OpenShiftClusterDocument, error) {
	c.lock.Lock()
	defer c.lock.Unlock()

	if c.err != nil {
		return nil, c.err
	}

	openShiftClusterDocument, err := c.deepCopy(openShiftClusterDocument) // copy now because pretriggers can mutate openShiftClusterDocument
	if err != nil {
		return nil, err
	}

	if options != nil {
		err := c.processPreTriggers(ctx, openShiftClusterDocument, options)
		if err != nil {
			return nil, err
		}
	}

	existingOpenShiftClusterDocument, exists := c.openShiftClusterDocuments[openShiftClusterDocument.ID]
	if isCreate && exists {
		return nil, &Error{
			StatusCode: http.StatusConflict,
			Message:    "Entity with the specified id already exists in the system",
		}
	}
	if !isCreate {
		if !exists {
			return nil, &Error{StatusCode: http.StatusNotFound}
		}

		if openShiftClusterDocument.ETag != existingOpenShiftClusterDocument.ETag {
			return nil, &Error{StatusCode: http.StatusPreconditionFailed}
		}
	}

	if c.conflictChecker != nil {
		for _, openShiftClusterDocumentToCheck := range c.openShiftClusterDocuments {
			if c.conflictChecker(openShiftClusterDocumentToCheck, openShiftClusterDocument) {
				return nil, &Error{
					StatusCode: http.StatusConflict,
					Message:    "Entity with the specified id already exists in the system",
				}
			}
		}
	}

	openShiftClusterDocument.ETag = fmt.Sprint(c.etag)
	c.etag++

	c.openShiftClusterDocuments[openShiftClusterDocument.ID] = openShiftClusterDocument

	if err = c.updateChangeFeeds(openShiftClusterDocument); err != nil {
		return nil, err
	}

	return c.deepCopy(openShiftClusterDocument)
}

// Create creates a OpenShiftClusterDocument in the database
func (c *FakeOpenShiftClusterDocumentClient) Create(ctx context.Context, partitionkey string, openShiftClusterDocument *pkg.OpenShiftClusterDocument, options *Options) (*pkg.OpenShiftClusterDocument, error) {
	return c.apply(ctx, partitionkey, openShiftClusterDocument, options, true)
}

// Replace replaces a OpenShiftClusterDocument in the database
func (c *FakeOpenShiftClusterDocumentClient) Replace(ctx context.Context, partitionkey string, openShiftClusterDocument *pkg.OpenShiftClusterDocument, options *Options) (*pkg.OpenShiftClusterDocument, error) {
	return c.apply(ctx, partitionkey, openShiftClusterDocument, options, false)
}

// List returns a OpenShiftClusterDocumentIterator to list all OpenShiftClusterDocuments in the database
func (c *FakeOpenShiftClusterDocumentClient) List(*Options) OpenShiftClusterDocumentIterator {
	c.lock.RLock()
	defer c.lock.RUnlock()

	if c.err != nil {
		return NewFakeOpenShiftClusterDocumentErroringRawIterator(c.err)
	}

	openShiftClusterDocuments := make([]*pkg.OpenShiftClusterDocument, 0, len(c.openShiftClusterDocuments))
	for _, openShiftClusterDocument := range c.openShiftClusterDocuments {
		openShiftClusterDocument, err := c.deepCopy(openShiftClusterDocument)
		if err != nil {
			return NewFakeOpenShiftClusterDocumentErroringRawIterator(err)
		}
		openShiftClusterDocuments = append(openShiftClusterDocuments, openShiftClusterDocument)
	}

	if c.sorter != nil {
		c.sorter(openShiftClusterDocuments)
	}

	return NewFakeOpenShiftClusterDocumentIterator(openShiftClusterDocuments, 0)
}

// ListAll lists all OpenShiftClusterDocuments in the database
func (c *FakeOpenShiftClusterDocumentClient) ListAll(ctx context.Context, options *Options) (*pkg.OpenShiftClusterDocuments, error) {
	iter := c.List(options)
	return iter.Next(ctx, -1)
}

// Get gets a OpenShiftClusterDocument from the database
func (c *FakeOpenShiftClusterDocumentClient) Get(ctx context.Context, partitionkey string, id string, options *Options) (*pkg.OpenShiftClusterDocument, error) {
	c.lock.RLock()
	defer c.lock.RUnlock()

	if c.err != nil {
		return nil, c.err
	}

	openShiftClusterDocument, exists := c.openShiftClusterDocuments[id]
	if !exists {
		return nil, &Error{StatusCode: http.StatusNotFound}
	}

	return c.deepCopy(openShiftClusterDocument)
}

// Delete deletes a OpenShiftClusterDocument from the database
func (c *FakeOpenShiftClusterDocumentClient) Delete(ctx context.Context, partitionKey string, openShiftClusterDocument *pkg.OpenShiftClusterDocument, options *Options) error {
	c.lock.Lock()
	defer c.lock.Unlock()

	if c.err != nil {
		return c.err
	}

	_, exists := c.openShiftClusterDocuments[openShiftClusterDocument.ID]
	if !exists {
		return &Error{StatusCode: http.StatusNotFound}
	}

	delete(c.openShiftClusterDocuments, openShiftClusterDocument.ID)
	return nil
}

// ChangeFeed is unimplemented
func (c *FakeOpenShiftClusterDocumentClient) ChangeFeed(*Options) OpenShiftClusterDocumentIterator {
	c.lock.RLock()
	defer c.lock.RUnlock()

	if c.err != nil {
		return NewFakeOpenShiftClusterDocumentErroringRawIterator(c.err)
	}

	newIter, ok := c.List(nil).(*fakeOpenShiftClusterDocumentIterator)
	if !ok {
		return NewFakeOpenShiftClusterDocumentErroringRawIterator(fmt.Errorf("internal error"))
	}

	c.changeFeedIterators = append(c.changeFeedIterators, newIter)
	return newIter
}

func (c *FakeOpenShiftClusterDocumentClient) updateChangeFeeds(openShiftClusterDocument *pkg.OpenShiftClusterDocument) error {
	for _, currentIterator := range c.changeFeedIterators {
		newTpl, err := c.deepCopy(openShiftClusterDocument)
		if err != nil {
			return err
		}
		currentIterator.openShiftClusterDocuments = append(currentIterator.openShiftClusterDocuments, newTpl)
		currentIterator.done = false
	}

	return nil
}

func (c *FakeOpenShiftClusterDocumentClient) processPreTriggers(ctx context.Context, openShiftClusterDocument *pkg.OpenShiftClusterDocument, options *Options) error {
	for _, triggerName := range options.PreTriggers {
		if triggerHandler := c.triggerHandlers[triggerName]; triggerHandler != nil {
			c.lock.Unlock()
			err := triggerHandler(ctx, openShiftClusterDocument)
			c.lock.Lock()
			if err != nil {
				return err
			}
		} else {
			return ErrNotImplemented
		}
	}

	return nil
}

// Query calls a query handler to implement database querying
func (c *FakeOpenShiftClusterDocumentClient) Query(name string, query *Query, options *Options) OpenShiftClusterDocumentRawIterator {
	c.lock.RLock()
	defer c.lock.RUnlock()

	if c.err != nil {
		return NewFakeOpenShiftClusterDocumentErroringRawIterator(c.err)
	}

	if queryHandler := c.queryHandlers[query.Query]; queryHandler != nil {
		c.lock.RUnlock()
		i := queryHandler(c, query, options)
		c.lock.RLock()
		return i
	}

	return NewFakeOpenShiftClusterDocumentErroringRawIterator(ErrNotImplemented)
}

// QueryAll calls a query handler to implement database querying
func (c *FakeOpenShiftClusterDocumentClient) QueryAll(ctx context.Context, partitionkey string, query *Query, options *Options) (*pkg.OpenShiftClusterDocuments, error) {
	iter := c.Query("", query, options)
	return iter.Next(ctx, -1)
}

func NewFakeOpenShiftClusterDocumentIterator(openShiftClusterDocuments []*pkg.OpenShiftClusterDocument, continuation int) OpenShiftClusterDocumentRawIterator {
	return &fakeOpenShiftClusterDocumentIterator{openShiftClusterDocuments: openShiftClusterDocuments, continuation: continuation}
}

type fakeOpenShiftClusterDocumentIterator struct {
	openShiftClusterDocuments []*pkg.OpenShiftClusterDocument
	continuation              int
	done                      bool
}

func (i *fakeOpenShiftClusterDocumentIterator) NextRaw(ctx context.Context, maxItemCount int, out interface{}) error {
	return ErrNotImplemented
}

func (i *fakeOpenShiftClusterDocumentIterator) Next(ctx context.Context, maxItemCount int) (*pkg.OpenShiftClusterDocuments, error) {
	if i.done {
		return nil, nil
	}

	var openShiftClusterDocuments []*pkg.OpenShiftClusterDocument
	if maxItemCount == -1 {
		openShiftClusterDocuments = i.openShiftClusterDocuments[i.continuation:]
		i.continuation = len(i.openShiftClusterDocuments)
		i.done = true
	} else {
		max := i.continuation + maxItemCount
		if max > len(i.openShiftClusterDocuments) {
			max = len(i.openShiftClusterDocuments)
		}
		openShiftClusterDocuments = i.openShiftClusterDocuments[i.continuation:max]
		i.continuation = max
		i.done = i.Continuation() == ""
	}

	return &pkg.OpenShiftClusterDocuments{
		OpenShiftClusterDocuments: openShiftClusterDocuments,
		Count:                     len(openShiftClusterDocuments),
	}, nil
}

func (i *fakeOpenShiftClusterDocumentIterator) Continuation() string {
	if i.continuation >= len(i.openShiftClusterDocuments) {
		return ""
	}
	return fmt.Sprintf("%d", i.continuation)
}

// NewFakeOpenShiftClusterDocumentErroringRawIterator returns a OpenShiftClusterDocumentRawIterator which
// whose methods return the given error
func NewFakeOpenShiftClusterDocumentErroringRawIterator(err error) OpenShiftClusterDocumentRawIterator {
	return &fakeOpenShiftClusterDocumentErroringRawIterator{err: err}
}

type fakeOpenShiftClusterDocumentErroringRawIterator struct {
	err error
}

func (i *fakeOpenShiftClusterDocumentErroringRawIterator) Next(ctx context.Context, maxItemCount int) (*pkg.OpenShiftClusterDocuments, error) {
	return nil, i.err
}

func (i *fakeOpenShiftClusterDocumentErroringRawIterator) NextRaw(context.Context, int, interface{}) error {
	return i.err
}

func (i *fakeOpenShiftClusterDocumentErroringRawIterator) Continuation() string {
	return ""
}
